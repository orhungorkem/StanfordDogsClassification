{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ahead-profile",
   "metadata": {},
   "source": [
    "# Stanford Dogs Classification with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-farmer",
   "metadata": {},
   "source": [
    "**Kernel:** The matrices iterated over the image with elementwise multiplication in convolution step. They help us to sharpen/blur the image or detect some specific features.  \n",
    "\n",
    "**Stride:** How much we iterate the feature map in each step of convolution.  \n",
    "\n",
    "**Pooling:** After convolution, we still preserve the spatial localites in our image. But it is not wanted. We want our network to recognize some features and patterns even though they are rotated, widened etc. This is also helpful to avoid overfitting. In pooling, we seperate the image into non overlapping pixel groups and pick a data from each group according to type of pooling. For example in max pooling, we pick the max pixel to get into resulting matrix. Getting the data by this helps us to determine a pattern even if it is located in somewhere else or in some other orientation in test image. Pooling also reduces the size of parameters.    \n",
    "\n",
    "**Padding:** It refers to the amount of pixels added to an image when it is being processed by the kernel of a CNN. Padding is applied to overcome the border effect problem. As we convolve through the image, we lose data on the edges. By padding, we add artificial pixels to the borders and centralize our features. Padding is not strictly necessary for large images but is improtant foro small images.  \n",
    "\n",
    "**Data generator:** A class of Keras that utilizes uploading the dataset into our model and ditributing the images into batches.   \n",
    "\n",
    "**Dropout:** It is a regularization method that approximates training a large number of neural networks with different architectures in parallel. It eliminates a proportion of neural weights in each propagation. \n",
    "\n",
    "**Image data augmentation:** Transforms that include a range of operations from the field of image manipulation, such as shifts, flips, zooms, and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-cycle",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/jessicali9530/stanford-dogs-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-disease",
   "metadata": {},
   "source": [
    "Paper about optimization: https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/  \n",
    "\n",
    "A full description: https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb  \n",
    "\n",
    "A detailed tutorial: https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/\n",
    "\n",
    "A basic train example: https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "\n",
    "Image kernels: https://setosa.io/ev/image-kernels/   \n",
    "\n",
    "Code reference: https://www.kaggle.com/hengzheng/dog-breeds-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separated-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-universal",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "featured-worship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16508 images belonging to 120 classes.\n",
      "Found 4072 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,  ## bu faydalı mı bilemedim\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./images/Images\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    \"./images/Images\", # same directory as training data\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-nevada",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confused-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "516/516 [==============================] - 71s 136ms/step - loss: 4.7506 - accuracy: 0.0173 - val_loss: 4.4233 - val_accuracy: 0.0386\n",
      "Epoch 2/12\n",
      "516/516 [==============================] - 69s 135ms/step - loss: 4.3137 - accuracy: 0.0504 - val_loss: 4.2321 - val_accuracy: 0.0643\n",
      "Epoch 3/12\n",
      "516/516 [==============================] - 69s 134ms/step - loss: 4.0791 - accuracy: 0.0869 - val_loss: 4.1238 - val_accuracy: 0.0766\n",
      "Epoch 4/12\n",
      "516/516 [==============================] - 69s 133ms/step - loss: 3.8759 - accuracy: 0.1165 - val_loss: 4.0837 - val_accuracy: 0.0891\n",
      "Epoch 5/12\n",
      "516/516 [==============================] - 69s 133ms/step - loss: 3.6813 - accuracy: 0.1489 - val_loss: 4.0513 - val_accuracy: 0.1022\n",
      "Epoch 6/12\n",
      "516/516 [==============================] - 72s 140ms/step - loss: 3.4587 - accuracy: 0.1915 - val_loss: 4.0401 - val_accuracy: 0.1041\n",
      "Epoch 7/12\n",
      "516/516 [==============================] - 68s 132ms/step - loss: 3.2425 - accuracy: 0.2378 - val_loss: 4.1124 - val_accuracy: 0.1022\n",
      "Epoch 8/12\n",
      "516/516 [==============================] - 69s 134ms/step - loss: 3.0290 - accuracy: 0.2803 - val_loss: 4.1237 - val_accuracy: 0.1108\n",
      "Epoch 9/12\n",
      "516/516 [==============================] - 68s 133ms/step - loss: 2.8383 - accuracy: 0.3209 - val_loss: 4.2192 - val_accuracy: 0.1110\n",
      "Epoch 10/12\n",
      "516/516 [==============================] - 70s 135ms/step - loss: 2.6345 - accuracy: 0.3593 - val_loss: 4.2427 - val_accuracy: 0.1144\n",
      "Epoch 11/12\n",
      "516/516 [==============================] - 69s 133ms/step - loss: 2.3978 - accuracy: 0.4000 - val_loss: 4.3398 - val_accuracy: 0.1189\n",
      "Epoch 12/12\n",
      "516/516 [==============================] - 68s 133ms/step - loss: 2.2844 - accuracy: 0.4402 - val_loss: 4.3902 - val_accuracy: 0.1221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27bb90497c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "# we do not add the input shape since it is not the input layer anymore\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
    "cnn.add(Dropout(0.2))   #0.2 of the inputs will be randomly excluded from each update cycle.\n",
    "cnn.add(tf.keras.layers.Dense(units=120, activation='softmax'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "cnn.fit(x = train_generator, validation_data = validation_generator, epochs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "revised-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "forbidden-pakistan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Type: bloodhound\n",
      "Predictions:\n",
      "dingo: 0.3430635\n",
      "basenji: 0.19292621\n",
      "Leonberg: 0.18629146\n",
      "dhole: 0.061713573\n",
      "Afghan_hound: 0.04099191\n",
      "\n",
      "\n",
      "Actual Type: redbone\n",
      "Predictions:\n",
      "redbone: 0.7349755\n",
      "bloodhound: 0.050924223\n",
      "Irish_terrier: 0.03833142\n",
      "golden_retriever: 0.018872371\n",
      "vizsla: 0.018436732\n",
      "\n",
      "\n",
      "Actual Type: miniature_schnauzer\n",
      "Predictions:\n",
      "Scottish_deerhound: 0.35837412\n",
      "keeshond: 0.09457108\n",
      "Irish_wolfhound: 0.08901828\n",
      "Weimaraner: 0.06453181\n",
      "miniature_schnauzer: 0.041819356\n",
      "\n",
      "\n",
      "Actual Type: Brabancon_griffon\n",
      "Predictions:\n",
      "Brabancon_griffon: 0.1443465\n",
      "Bernese_mountain_dog: 0.14097139\n",
      "boxer: 0.10542709\n",
      "collie: 0.086436845\n",
      "Yorkshire_terrier: 0.03927331\n",
      "\n",
      "\n",
      "Actual Type: African_hunting_dog\n",
      "Predictions:\n",
      "African_hunting_dog: 0.48388088\n",
      "Greater_Swiss_Mountain_dog: 0.19346884\n",
      "Norwegian_elkhound: 0.04793422\n",
      "bluetick: 0.039568275\n",
      "Walker_hound: 0.025860952\n",
      "\n",
      "\n",
      "Actual Type: Sussex_spaniel\n",
      "Predictions:\n",
      "Sussex_spaniel: 0.60307276\n",
      "redbone: 0.031826302\n",
      "Rhodesian_ridgeback: 0.031076202\n",
      "silky_terrier: 0.027179312\n",
      "curly-coated_retriever: 0.027107544\n",
      "\n",
      "\n",
      "Actual Type: Walker_hound\n",
      "Predictions:\n",
      "basenji: 0.09850342\n",
      "Greater_Swiss_Mountain_dog: 0.08674525\n",
      "beagle: 0.0823628\n",
      "Chihuahua: 0.0762676\n",
      "Blenheim_spaniel: 0.06941086\n",
      "\n",
      "\n",
      "Actual Type: Lhasa\n",
      "Predictions:\n",
      "Norwegian_elkhound: 0.12452805\n",
      "malamute: 0.11579315\n",
      "Shih-Tzu: 0.060742404\n",
      "African_hunting_dog: 0.05000077\n",
      "miniature_schnauzer: 0.0443165\n",
      "\n",
      "\n",
      "Actual Type: Irish_terrier\n",
      "Predictions:\n",
      "Irish_terrier: 0.90762126\n",
      "Irish_setter: 0.03530798\n",
      "vizsla: 0.01199632\n",
      "miniature_schnauzer: 0.009306302\n",
      "beagle: 0.0047255713\n",
      "\n",
      "\n",
      "Actual Type: bluetick\n",
      "Predictions:\n",
      "bluetick: 0.8833651\n",
      "basenji: 0.0814446\n",
      "whippet: 0.011594253\n",
      "Boston_bull: 0.0043389476\n",
      "Norwegian_elkhound: 0.0040455433\n",
      "\n",
      "\n",
      "Actual Type: cairn\n",
      "Predictions:\n",
      "African_hunting_dog: 0.28669593\n",
      "Doberman: 0.17299634\n",
      "miniature_schnauzer: 0.08173982\n",
      "French_bulldog: 0.07872069\n",
      "cairn: 0.0619218\n",
      "\n",
      "\n",
      "Actual Type: borzoi\n",
      "Predictions:\n",
      "collie: 0.29190898\n",
      "Pembroke: 0.12665226\n",
      "Chihuahua: 0.09990622\n",
      "dingo: 0.04728333\n",
      "bull_mastiff: 0.04681254\n",
      "\n",
      "\n",
      "Actual Type: miniature_schnauzer\n",
      "Predictions:\n",
      "miniature_schnauzer: 0.44568253\n",
      "Eskimo_dog: 0.115057796\n",
      "French_bulldog: 0.075688876\n",
      "pug: 0.04520031\n",
      "Lakeland_terrier: 0.037746612\n",
      "\n",
      "\n",
      "Actual Type: toy_terrier\n",
      "Predictions:\n",
      "toy_terrier: 0.22742859\n",
      "collie: 0.089227214\n",
      "Bernese_mountain_dog: 0.0871746\n",
      "Lakeland_terrier: 0.04881868\n",
      "EntleBucher: 0.031215541\n",
      "\n",
      "\n",
      "Actual Type: German_short-haired_pointer\n",
      "Predictions:\n",
      "German_short-haired_pointer: 0.6703503\n",
      "Chesapeake_Bay_retriever: 0.08563819\n",
      "Lakeland_terrier: 0.04107259\n",
      "Scottish_deerhound: 0.016833542\n",
      "Siberian_husky: 0.016404567\n",
      "\n",
      "\n",
      "Actual Type: Tibetan_mastiff\n",
      "Predictions:\n",
      "Tibetan_mastiff: 0.30324525\n",
      "flat-coated_retriever: 0.09910403\n",
      "Staffordshire_bullterrier: 0.08803236\n",
      "Irish_wolfhound: 0.07214936\n",
      "Scottish_deerhound: 0.05754586\n",
      "\n",
      "\n",
      "Actual Type: briard\n",
      "Predictions:\n",
      "pug: 0.19099124\n",
      "miniature_schnauzer: 0.17131637\n",
      "Weimaraner: 0.07031537\n",
      "Eskimo_dog: 0.06619006\n",
      "Lhasa: 0.04708441\n",
      "\n",
      "\n",
      "Actual Type: groenendael\n",
      "Predictions:\n",
      "groenendael: 0.5516783\n",
      "pug: 0.048827235\n",
      "Newfoundland: 0.04692965\n",
      "Scotch_terrier: 0.031078743\n",
      "Mexican_hairless: 0.023517134\n",
      "\n",
      "\n",
      "Actual Type: cairn\n",
      "Predictions:\n",
      "Eskimo_dog: 0.24088192\n",
      "Samoyed: 0.1797668\n",
      "cairn: 0.060366478\n",
      "Labrador_retriever: 0.05441788\n",
      "English_setter: 0.04963463\n",
      "\n",
      "\n",
      "Actual Type: Norwegian_elkhound\n",
      "Predictions:\n",
      "Norwegian_elkhound: 0.7842013\n",
      "bluetick: 0.032525018\n",
      "toy_terrier: 0.029915122\n",
      "French_bulldog: 0.023653755\n",
      "giant_schnauzer: 0.023218669\n",
      "\n",
      "\n",
      "The rate of reaching the correct type in first 5 predictions: 0.75\n"
     ]
    }
   ],
   "source": [
    "path = './images/Images/'\n",
    "num_tests = 20\n",
    "counter = 0  #counts the accuracy in first 5 predictions\n",
    "\n",
    "for i in range(num_tests):\n",
    "    \n",
    "    x = np.random.randint(len(os.listdir(path)))\n",
    "    type_name = os.listdir(path)[x]\n",
    "    newpath = path+type_name+'/'\n",
    "    x = np.random.randint(len(os.listdir(newpath)))\n",
    "    image_name = os.listdir(newpath)[x]\n",
    "    newpath +=image_name\n",
    "    \n",
    "    img = image.load_img(newpath, target_size=(64, 64))\n",
    "    img_array = image.img_to_array(img)/255\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    pred = cnn.predict(img_batch)\n",
    "    mapping = train_generator.class_indices\n",
    "    j = 0\n",
    "    for key in mapping:\n",
    "        mapping[key] = pred[0][j]\n",
    "        j+=1\n",
    "        \n",
    "    mapping = dict(sorted(mapping.items(), key=lambda item: item[1],reverse = True))\n",
    "    typeshort = type_name[type_name.find(\"-\")+1:]\n",
    "    text1 = \"Actual Type: \"+ typeshort\n",
    "    text2 =\"\"\n",
    "    text2 +=\"Predictions:\\n\"\n",
    "    j = 0\n",
    "    for key in mapping:\n",
    "        if(j==5):\n",
    "            break\n",
    "        text2 += key[key.find(\"-\")+1:]+\": \"+str(mapping[key])+\"\\n\"\n",
    "        j+=1\n",
    "    \n",
    "    print(text1)\n",
    "    print(text2)\n",
    "    print(\"\")\n",
    "    if(typeshort in text2):\n",
    "        counter+=1\n",
    "    \n",
    "    img2 = cv2.imread(newpath,0)\n",
    "    cv2.imshow(type_name[type_name.find(\"-\")+1:] ,img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "print(\"The rate of reaching the correct type in first 5 predictions: \"+str(counter/num_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-implement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
